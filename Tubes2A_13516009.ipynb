{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart Disease Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kelompok Bernat tidur 2\n",
    "#### Rahmat Nur Ibrahim Santosa / 13516009\n",
    "#### Michelle Eliza Gananjaya / 13516015\n",
    "#### Erma Safira Nurmasyita / 13516072\n",
    "#### Daniel Ryan Levyson / 13516132\n",
    "#### Rinda Nur Hafizha / 13516151"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metode Cleaning\n",
    "Pertama-tama, dihitung jumlah nilai `'?'` pada tiap kolom. Jika banyaknya melebihi setengah dari jumlah data, maka kolom tersebut tidak diikutsertakan pada proses training.\n",
    "\n",
    "Untuk menangani nilai `'?'` pada setiap kolom lainnya, jika nilai suatu kolom numerikal, nilai `'?'` diganti menjadi nilai median dari nilai pada kolom tersebut. Jika niali suatu kolom kategorikal, nilai `'?'` diganti menjadi nilai modus dari nilai-nilai pada kolom tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATASET TRAIN AND TEST\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = pd.read_csv('data/tubes2_HeartDisease_train.csv')\n",
    "test_set = pd.read_csv('data/tubes2_HeartDisease_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# DATASET ClEANING\n",
    "# Column Dataset Train, No. of '?' values\n",
    "## Column 4 = 46 kosong - numerical\n",
    "## Column 5 = 24 - numerical\n",
    "## Column 6 = 78 - categorical\n",
    "## Column 7 = 1 - categorical, replace with 0\n",
    "## Column 8 = 43 - numerical\n",
    "## Column 9 = 43 - categorical\n",
    "## Column 10 = 48 - numerical\n",
    "## Column 11 = 261 - categorical\n",
    "## Column 12 = 513 - DROP\n",
    "## Column 13 = 407 - DROP\n",
    "\n",
    "# Drop column 12 and 13\n",
    "import math\n",
    "dataset = dataset.drop(columns=['Column12', 'Column13'], axis=1)\n",
    "test_set = test_set.drop(columns=['Column12', 'Column13'])\n",
    "\n",
    "# Replace '?' value in Column7 with 0\n",
    "data_len = len(dataset['Column7'])\n",
    "for i in range(0, data_len):\n",
    "    if dataset['Column7'][i] == '?' or math.isnan(float(dataset['Column7'][i])):\n",
    "        dataset['Column7'][i] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Replace '?' with nan\n",
    "col = 'Column'\n",
    "for i in range(1, 12):\n",
    "    column = col + str(i)\n",
    "    for j in range(0, data_len):\n",
    "        if dataset[column][j] == '?':\n",
    "            dataset[column][j] = np.nan\n",
    "\n",
    "#dataset = dataset.drop(deleterow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Replace nan in categorical data with mode value (Column 6, 9, 11)\n",
    "mode6 = dataset['Column6'].mode()\n",
    "mode9 = dataset['Column9'].mode()\n",
    "mode11 = dataset['Column11'].mode()\n",
    "for i in range(0, data_len):\n",
    "    if math.isnan(float(dataset['Column6'][i])):\n",
    "        dataset['Column6'][i] = mode6\n",
    "for i in range(0, data_len):\n",
    "    if math.isnan(float(dataset['Column9'][i])):\n",
    "        dataset['Column9'][i] = mode9\n",
    "for i in range(0, data_len):\n",
    "    if math.isnan(float(dataset['Column11'][i])):\n",
    "        dataset['Column11'][i] = mode11\n",
    "        \n",
    "# Replace nan in numerical data with median value (Column 4, 5, 8, 10)\n",
    "median4 = dataset['Column4'].median()\n",
    "median5 = dataset['Column5'].median()\n",
    "median8 = dataset['Column8'].median()\n",
    "median10 = dataset['Column10'].median()\n",
    "for i in range(0, data_len):\n",
    "    if math.isnan(float(dataset['Column4'][i])):\n",
    "        dataset['Column4'][i] = median4\n",
    "for i in range(0, data_len):\n",
    "    if math.isnan(float(dataset['Column5'][i])):\n",
    "        dataset['Column5'][i] = median5\n",
    "for i in range(0, data_len):\n",
    "    if math.isnan(float(dataset['Column8'][i])):\n",
    "        dataset['Column8'][i] = median8\n",
    "for i in range(0, data_len):\n",
    "    if math.isnan(float(dataset['Column10'][i])):\n",
    "        dataset['Column10'][i] = median10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def generate_fold(k, dataset):\n",
    "    dataset_size = len(dataset)\n",
    "    fold = [[] for i in range (k)]\n",
    "    nums = [i for i in range(k)]\n",
    "    sizes = [0 for i in range(k)]\n",
    "    normal_size = math.floor(dataset_size / k)\n",
    "    max_size = math.ceil(dataset_size / k)\n",
    "    size = max_size\n",
    "    max_size_counter = dataset_size % k\n",
    "    \n",
    "    for val in dataset:\n",
    "        idx = choice(nums)\n",
    "        fold[idx].append(val)\n",
    "        sizes[idx] += 1\n",
    "        \n",
    "        if sizes[idx] == size:\n",
    "            nums.remove(idx)\n",
    "        \n",
    "        if sizes[idx] == max_size:\n",
    "            max_size_counter -= 1\n",
    "            if max_size_counter == 0:\n",
    "                size = normal_size\n",
    "                \n",
    "                temp = []\n",
    "                for num in nums:\n",
    "                    if sizes[num] == size:\n",
    "                        temp.append(num)\n",
    "                for t in temp:\n",
    "                    nums.remove(t)\n",
    "    return fold\n",
    "\n",
    "def seperate(dataset):\n",
    "    params = []\n",
    "    lables = []\n",
    "    datasize = len(dataset[0])\n",
    "    for data in dataset:\n",
    "        params.append(data[:datasize-1])\n",
    "        lables.append(data[datasize-1])\n",
    "    return params, lables\n",
    "\n",
    "def parse_dataset(frame):\n",
    "    dataset = []\n",
    "    for index, row in frame.iterrows():\n",
    "        dataset.append(row.values.tolist())\n",
    "    return dataset\n",
    "\n",
    "def get_trainingset(index, folds):\n",
    "    training_set = []\n",
    "    for i in range(len(folds)):\n",
    "        if i != index:\n",
    "            for data in folds[i]:\n",
    "                training_set.append(data)\n",
    "    return training_set\n",
    "\n",
    "def pseudo_clean(dataset):\n",
    "    cleaned = []\n",
    "    idx = 0\n",
    "    for data in dataset:\n",
    "        row = []\n",
    "        for val in data:\n",
    "            row.append(float(val))\n",
    "        cleaned.append(row)\n",
    "        idx += 1\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "\n",
    "def train(trainer, folds):\n",
    "    classifiers = []\n",
    "    for i in range (len(folds)):\n",
    "        training_set = get_trainingset(i, folds)\n",
    "        training_params, training_lables = seperate(training_set)\n",
    "        classifiers.append(trainer.fit(training_params, training_lables))\n",
    "    return classifiers\n",
    "\n",
    "def train_naive_bayes(folds):\n",
    "    return train(GaussianNB(), folds)\n",
    "\n",
    "def train_decision_tree(folds):\n",
    "    return train(tree.DecisionTreeClassifier(), folds)\n",
    "\n",
    "def train_knn(neighbor, folds):\n",
    "    return train(KNeighborsClassifier(neighbor), folds)\n",
    "\n",
    "def train_mlp(folds):\n",
    "    return train(MLPClassifier(learning_rate_init=0.01, max_iter=300), folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = parse_dataset(dataset)\n",
    "dataset = pseudo_clean(dataset)\n",
    "folds = generate_fold(10, dataset)\n",
    "\n",
    "nb_models = train_naive_bayes(folds)\n",
    "dt_models = train_decision_tree(folds)\n",
    "knn_models = train_knn(3, folds)\n",
    "mlp_models = train_mlp(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def generate_accuracies(models):\n",
    "    for i in range(len(models)):\n",
    "        test_set = folds[i]\n",
    "        test_params, test_lables = seperate(test_set)\n",
    "        predictions = models[i].predict(test_params)\n",
    "        accuracy = accuracy_score(np.array(test_lables), predictions)\n",
    "        print(str(round(accuracy * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracies:\n",
      "56.41%\n",
      "47.44%\n",
      "52.56%\n",
      "70.51%\n",
      "53.85%\n",
      "62.82%\n",
      "55.13%\n",
      "57.69%\n",
      "72.73%\n",
      "53.85%\n",
      "Decision Tree Accuracies:\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "47.44%\n",
      "K-Nearest Neighbors Accuracies:\n",
      "65.38%\n",
      "64.1%\n",
      "62.82%\n",
      "76.92%\n",
      "66.67%\n",
      "62.82%\n",
      "64.1%\n",
      "70.51%\n",
      "68.83%\n",
      "47.44%\n",
      "Multi-Layer Perceptron Accuracies:\n",
      "48.72%\n",
      "47.44%\n",
      "48.72%\n",
      "48.72%\n",
      "30.77%\n",
      "47.44%\n",
      "41.03%\n",
      "42.31%\n",
      "53.25%\n",
      "42.31%\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Accuracies:\")\n",
    "generate_accuracies(nb_models)\n",
    "print(\"Decision Tree Accuracies:\")\n",
    "generate_accuracies(dt_models)\n",
    "print(\"K-Nearest Neighbors Accuracies:\")\n",
    "generate_accuracies(knn_models)\n",
    "print(\"Multi-Layer Perceptron Accuracies:\")\n",
    "generate_accuracies(mlp_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menyimpan Model ke File Eksternal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mlp_models.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(nb_models, 'nb_models.joblib')\n",
    "joblib.dump(dt_models, 'dt_models.joblib')\n",
    "joblib.dump(knn_models, 'knn_models.joblib')\n",
    "joblib.dump(mlp_models, 'mlp_models.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Analisis Hasil Training\n",
    "Berdasarkan accuracy dari hasil prediksi tiap model, model Decision Tree adalah yang terbaik karena memiliki hasil yang paling bagus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluasi model terbaik yang telah disimpan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'), DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')]\n"
     ]
    }
   ],
   "source": [
    "model_dt = joblib.load('dt_models.joblib')\n",
    "print(model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "47.44%\n"
     ]
    }
   ],
   "source": [
    "generate_accuracies(model_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
